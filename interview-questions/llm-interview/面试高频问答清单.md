# LLM 岗位面试高频问答清单（扩展版）

## 1. 模型与预训练（20问）
1) 多头注意力为何有效？
- 将表示空间分解为多个子空间，捕获互补特征；提升表示能力与稳定性。
2) 自注意力复杂度瓶颈？
- O(n^2)；可用稀疏注意力、线性注意力、块稀疏、滑动窗口缓解。
3) 位置编码选择？
- 绝对（Sinusoidal/learned）与相对（RoPE/ALiBi）；长上下文更偏相对。
4) Pre-LN vs Post-LN？
- Pre-LN 稳定易训练；Post-LN 峰值更高但不稳，现代模型多用 Pre-LN。
5) 激活函数选择？
- GELU/SiLU 常用；影响平滑性与训练稳定。
6) 预训练目标差异？
- CLM：生成类任务；MLM：理解类；Span：T5风格，适配抽取/生成混合。
7) 长上下文扩展？
- RoPE scaling、NTK scaling、分块注意力、位置插值、ALiBi。
8) 混合精度与数值稳定？
- bf16 优先；梯度裁剪、loss scale、RMSNorm 提升稳定。
9) 参数规模与数据需求？
- Chinchilla 最优；更大模型需要更多token避免欠拟合。
10) Checkpoint 策略？
- 局部+全量；异步存储；含优化器状态以支持断点续训。
11) Flash-Attn 的要点？
- 重排计算与 IO 最小化；显著提升吞吐并减少显存。
12) 归一化选择？
- LayerNorm vs RMSNorm；后者更省计算且稳定。
13) 权重初始化？
- Scaled init/μParam；避免深层梯度退化。
14) 正则化？
- Dropout、Label Smoothing、R-Drop、数据增强。
15) 数据配比？
- 多域分层采样；温度混合；避免单域过拟合。
16) 评估集设计？
- 任务/安全/稳健性多维；去污染；时间切分。
17) Prompt 格式影响？
- 模板一致性、特殊token、分隔符显著影响风格/损失。
18) 共享词表与多语？
- SentencePiece/BPE；保留特殊token；避免稀有语种退化。
19) 旋转位置编码细节？
- RoPE 频率缩放需与KV缓存一致更新；避免错位。
20) 预训练语料版权与合规？
- 许可审计、屏蔽敏感域、合规留痕。

## 2. 数据准备与清洗（22问）
1) 如何度量数据质量与设置阈值？
2) 如何做跨语料去重与泄漏防护？
3) 如何设计安全过滤（PII/毒性/越狱）？
4) 多域数据的采样与重加权策略？
5) 多轮对话模板如何统一与对齐？
6) 如何构建困难样本与对抗样本？
7) 事实性校验如何自动化？
8) 指令数据常见噪声类型与修复？
9) 人评一致性如何量化（Kappa/IAA）？
10) 在线日志如何转化为高质量SFT数据？
11) 如何避免评测集污染？
12) 多语言数据如何对齐与平衡？

## 3. 微调与对齐（SFT/PEFT/QLoRA/DPO 等 24问）
1) SFT loss 只对 assistant 段落计算的理由？
- 防止模型模仿用户输入；确保指令遵循。
2) LoRA rank/alpha/dropout 如何选？
- 简单任务 r=4/8，复杂任务 r=16；alpha≈2r；dropout≤0.1。
3) QLoRA 为什么用 NF4？
- 对非高斯分布更鲁棒；配合 double quant 减少误差。
4) LoRA+QLoRA 组合常见坑？
- weight decay、量化核不兼容、pad_token设置遗漏。
5) DPO 参考模型作用？
- 提供KL正则基线，稳定优化，防止塌缩。
6) ORPO 相较DPO的稳健性来源？
- 胜算比形式减弱极端样本影响。
7) KTO 如何提升安全？
- 区分正负样本权重，强化拒绝危险指令。
8) 多Adapter路由何时用？
- 多域/多风格任务；可做 gating 或简单 heuristic。
9) 指标如何选？
- 任务（EM/F1/ROUGE）+ 人评 + 安全（jailbreak/toxicity）。
10) 样式漂移监控？
- 风格embedding/词分布漂移；设阈告警。
11) 长上下文 SFT？
- packing/分块/稀疏注意力；控制峰值显存。
12) 多任务损失加权？
- 不确定性加权/动态 reweight；防止主任务退化。
13) R-Drop/Label Smoothing 的利弊？
- 提升泛化，但可能影响生成确定性。
14) RLHF 何时优于 DPO？
- 需显式约束/复杂奖励时；DPO成本更低。
15) 过拟合检测？
- Val ppl 与人评背离、重复生成增加、n-gram 重复。
16) 训练稳定技巧？
- 梯度裁剪、低lr、warmup、冻结embedding。
17) 合并导出注意？
- merge_and_unload 后保存；一致的dtype与词表。
18) 选择全参微调的场景？
- 大改架构/域内强迁移；有充足算力。
19) 安全对齐与拒答策略？
- 规则/模型判别 + 替代建议 + 最小暴露。
20) 数据漂移应对？
- 在线蒸馏/增量SFT；回放老数据。
21) 评估预算不足？
- 小样本人评 + 自动指标回归拟合。
22) 训练中崩溃恢复？
- 保存optimizer+scheduler；设置max_restarts。
23) 模型可解释？
- 注意力可视/梯度归因；有限帮助，重在监控。
24) 指令模板迁移？
- 统一特殊token与role，逐步迁移并做A/B。

## 4. 分布式训练与性能（20问）
1) ZeRO-1/2/3 区别与显存收益？
- 逐步分片优化器/梯度/权重，ZeRO-3 最大节省。
2) FSDP auto-wrap 策略？
- 仅包裹大块（attn/mlp），减少通信与重建开销。
3) 3D 并行落地？
- TP+PP+DP 按集群拓扑映射；重叠通信与计算。
4) Activation checkpointing 的权衡？
- 降显存增算力；关注wall-clock提升是否正收益。
5) I/O 与数据管线？
- mmap/流水读取/预取；避免dataloader瓶颈。
6) Profiler 关注项？
- AllReduce 等待、Kernel 时间、HtoD 拷贝、显存碎片。
7) NCCL 调优？
- 环/树算法、网卡绑定、IB/UCX、NCCL_PROTO/TUNING。
8) 混合精度坑？
- bf16更稳；fp16需loss scale；确保算子支持。
9) Checkpoint/Resume 一致性？
- 固定随机种+数据顺序；保存优化器状态。
10) Async IO 与容错？
- 异步保存、多副本；torchrun --max-restarts。
11) Flash-Attn/SDPA 选择？
- 根据硬件与版本；统一到更快的实现。
12) Sequence packing？
- 同步label对齐；大幅提升吞吐。
13) ZeRO-Offload 何时启用？
- 显存不足时；注意CPU瓶颈与带宽。
14) 张量并行切分？
- qkv/out/MLP 切分；避免跨节点通信。
15) 混部与调度？
- 优先队列+温度/功耗限制；平衡吞吐/成本。
16) 长序列训练？
- 分块/Flash-Attn-2/三角mask优化。
17) 动态规模训练？
- scale up/down；注意BN统计/学习率策略。
18) 评测回归？
- 在同一固定seed/prompt集合；避免噪声。
19) 训练失败模式？
- 梯度爆炸/NaN、死锁、显存碎片；对应缓解策略。
20) 代码健壮性？
- 单元测试、断言、超参验证、配置快照。

## 5. 推理优化（20问）
1) KV 缓存设计？
- 分层/分页、RoPE 偏移一致、跨请求复用策略。
2) 连续批处理的收益？
- 显著提升吞吐；但增加排队延迟，需要SLA分级。
3) 推测解码关键参数？
- k、draft温度、接受率；对吞吐/质量的平衡。
4) Prefix cache？
- 共享公共前缀；节省重复计算。
5) PagedAttention？
- 将KV放入分页管理，减少碎片，支持长上下文。
6) 流式输出？
- 分片传输/心跳；与批处理权衡。
7) 多租户治理？
- 限流/配额/优先级；隔离爆发流量。
8) 温控与功耗？
- 降频/均衡分配；避免热失效。
9) A/B灰度？
- 指标：采纳率、质量、人评；控制实验。
10) 工具链选择？
- vLLM vs LMDeploy：kernel与生态差异。
11) Prompt路由？
- 易题走小模型；难题走大模型；设置信心阈。
12) 上下文压缩？
- 摘要/聚类/语义裁剪；降token成本。
13) KV持久化？
- 会话级KV缓存；注意隐私与隔离。
14) 异常恢复？
- 超时/重试/降级；幂等设计。
15) 高可用？
- 多AZ部署、健康检查、熔断。
16) 观测性？
- 指标、日志、Trace；Prompt与输出存档。
17) 安全防护？
- 注入检测、内容过滤、输出水印。
18) 质量退化监控？
- 在线指标趋势、人评抽检。
19) 形态学优化？
- FP8/INT4 结合；KV压缩；核融合。
20) 端侧/边缘推理？
- 量化+蒸馏，带宽/功耗优化。

## 6. 量化与部署（20问）
1) GPTQ/AWQ 差异？
- 误差目标与激活关注不同；AWQ更稳健。
2) 校准集选择？
- 代表性样本、覆盖分布尾部、任务相关。
3) SmoothQuant 作用？
- 激活峰值迁移到权重，利于激活量化。
4) Kernel 支持与兼容？
- cutlass/flash-attn/专用matmul；版本敏感。
5) vLLM/LMDeploy 支持差异？
- 批处理/分页/KV策略/插件生态不同。
6) INT8/INT4 折中？
- 质量 vs 吞吐；任务/长度敏感。
7) KV 与量化兼容？
- 需要量化感知KV或保持KV高精度。
8) 混合精度推理？
- 关键路径高精度，非关键低精度。
9) 回退策略？
- 质量劣化触发回退到更高精度。
10) TCO 衡量？
- 成本=GPU时+能耗+人力；综合评估。
...（其余项可按需要继续扩展）
