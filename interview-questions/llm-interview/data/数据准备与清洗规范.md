# 数据准备与清洗规范（LLM 指令/对话数据）

## 一、目标与范围
- 面向 SFT/DPO 等微调与对齐任务
- 输出高质量、可复用、可审计的数据集

## 二、数据格式
- 单轮指令：`{"instruction","input","output"}`
- 多轮对话（ChatML/GGUF）：统一 role 标签与特殊token
- 推荐字段：`id, source, domain, lang, quality_score, safety_tag`

## 三、清洗流程
1) 基础清洗：去重（SimHash/MinHash）、乱码/HTML 清理、长度/语言检测
2) 安全过滤：PII、毒性、仇恨、色情、违法（正则+LLM分类+关键词）
3) 事实性：日期过期检测、URL可用性、知识版本标注
4) 一致性：样式/格式统一，模板化对齐

## 四、质量评估与打分
- 维度：相关性、完整性、可执行性、事实性、安全性、多样性
- 打分策略：规则分 + 模型打分（NLI/Reward 模型）+ 人工抽检
- 保留 `quality_score`，阈值过滤（如 <0.6 丢弃）

## 五、采样与重加权
- 多域分层采样；低资源域上采样；困难样本加权
- 温度采样混合不同数据源：`p_i^\tau / sum p_j^\tau`

## 六、去重与泄漏防护
- 近重复与跨源泄漏检测；与评测集、线上语料隔离
- 语义去重：向量索引 + 局部敏感哈希（LSH）

## 七、标注与审计
- 保留 `source`、抽样日志、规则版本；可回溯
- 人评协议：一致性系数（Cohen's kappa）≥ 0.7

## 八、数据管线示例（Python）
```python
from dataclasses import dataclass
from typing import List, Dict
import re, json

@dataclass
class Record:
    instruction: str
    input: str
    output: str
    meta: Dict

def is_valid_lang(text: str) -> bool:
    return 5 < len(text) < 4000

def clean_html(text: str) -> str:
    return re.sub(r"<[^>]+>", " ", text)

def pipeline(records: List[Record]) -> List[Record]:
    cleaned = []
    seen = set()
    for r in records:
        key = hash((r.instruction.strip(), r.input.strip()))
        if key in seen:
            continue
        seen.add(key)
        if not (is_valid_lang(r.instruction) and is_valid_lang(r.output)):
            continue
        r.instruction = clean_html(r.instruction)
        r.output = clean_html(r.output)
        # TODO: PII/毒性过滤、NLI一致性校验、质量打分
        cleaned.append(r)
    return cleaned

if __name__ == "__main__":
    data = [Record("解释Transformer", "", "...", {"source":"wiki"})]
    out = pipeline(data)
    print(json.dumps([r.__dict__ for r in out], ensure_ascii=False, indent=2))
```

## 九、面试要点
- 解释如何量化“质量分”与“安全分”，以及阈值选择依据
- 描述去重与防泄漏方案（hash+向量两级）
- 展示多域采样/重加权策略对效果的提升
