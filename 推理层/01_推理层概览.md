### 01 推理层概览

本篇聚焦于“大模型推理层”的定义、关键目标与全景图，帮助你建立整体认知。

#### 推理层是什么
- 推理层是承载大模型在线/离线推断服务的工程化体系，连接上游应用（API、Agent、RAG、工具调用）与下游算力资源（GPU/CPU/专用加速器）。
- 核心职责：吞吐与时延优化、稳定与弹性、成本与安全控制、体验与一致性保障。

#### 典型工作负载
- 文本生成（Chat/Completion）、函数调用/工具调用、对话保持（多轮上下文）、结构化抽取、代码补全、对齐推理（如DPO/ORPO后模型的推断）。

#### 关键目标
- 性能：低时延、稳定吞吐、可扩展并发。
- 可靠：容错、自愈、灰度、回滚、限流与熔断。
- 经济：高效利用显存/内存/带宽，批处理与共享缓存，精益计费与成本优化。
- 体验：流式输出、工具与RAG协同、结果一致性。

#### 推理全景图（从请求到响应）
1) 接入层：鉴权、路由、限流、AB/灰度、观测埋点。
2) 编排层：会话管理、RAG检索/重排、函数调用、提示工程。
3) 推理服务：调度与批处理、KV缓存、并行化、量化/张量RT、显存管理。
4) 资源层：GPU/CPU/加速卡、集群与作业编排（K8s/Slurm/Ray）。
5) 观测与SRE：监控、日志、追踪、容量/弹性、成本计量。

#### 成功度量
- P50/P95/P99时延、吞吐（tokens/s, req/s）、SLA可用性、错误率、成本（$/token / $/req）、体验指标（延迟首字节TTFT、打字感）。

#### 与训练/微调的区别
- 训练/微调关注离线优化与吞吐（大批量、Checkpoint、分布式训练）。
- 推理关注在线SLA与交互体验（低延迟、稳定速率、弹性扩缩），工程手段差异更大。


