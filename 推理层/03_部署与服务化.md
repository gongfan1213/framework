### 03 部署与服务化（Serving）实践

本篇覆盖部署形态、服务接口与上线策略。

#### 部署形态
- 单机开发：Docker + 单GPU，便于调试。
- 生产集群：K8s + GPU节点池，结合NodeFeatureDiscovery/Topology Aware。
- 任务队列/分布式：Ray/Slurm/自研调度器，混部与弹性。

#### 服务接口
- REST/WS：OpenAI兼容API、SSE流式响应；gRPC用于低延迟与二进制传输。
- 模型路由：基于路径/参数/权重路由；多Region与多集群Geo路由。
- 鉴权与配额：API Key、OAuth、请求签名、租户级QPS/TPS/Token配额。

#### 上线策略
- 蓝绿/灰度/金丝雀：逐步扩大流量暴露风险；配合自动回滚。
- 只读权重映射：容器快速拉起，借助权重层缓存（如S3+本地缓存）。
- 预热与健康检查：加载权重与KV内核预热；Liveness/Readiness/Startup探针。

#### 配置与参数管理
- 模型与并行策略参数化（tensor/pipeline/专家数）；环境隔离（dev/stage/prod）。
- 运行时可调：温度、TopK/TopP、Max Tokens、止词、频率/存在惩罚、采样种子。

#### 成本与算力规划
- 选择合适的GPU（显存、带宽、NVLink/PCIe拓扑）；按负载弹性扩缩；按SLA选混精度与量化策略。


