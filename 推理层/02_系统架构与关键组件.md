### 02 系统架构与关键组件

本篇从架构视角梳理推理服务的分层与组件职责。

#### 分层架构
- 接入层（API Gateway）：鉴权、配额、限流、熔断、重试、流式传输、负载均衡。
- 业务编排层（Orchestrator）：会话与状态、提示管理、RAG、工具调用、函数/插件协议。
- 推理服务层（Serving）：模型加载、权重管理、Tokenizer、KV缓存、批处理、调度、并行化策略。
- 加速与内存层：张量RT（TensorRT-LLM）、FasterTransformer、vLLM、PagedAttention、量化内核。
- 资源/集群层：K8s/Slurm/Ray调度、GPU拓扑感知、Pod亲和性、拓扑与NUMA优化。
- 观测与治理：监控（Metrics/Logs/Tracing）、A/B实验、SLO/SLA、成本/用量计费、访问审计。

#### 关键组件说明
- Tokenizer与分词缓存：避免重复分词开销；长上下文协同分词。
- KV Cache管理：生命周期、复用策略、跨请求共享（同Prompt/前缀）、分页化内存管理。
- 批处理与调度器：Dynamic Batching、请求合并/拆分、优先级与公平调度、超时与撤销。
- 并行化：张量并行、流水并行、专家并行（MoE）、流水线阶段内的调度与通信。
- 量化与内核：INT8/4、AWQ/GPTQ、TensorRT、FlashAttention、Cutlass内核、PagedAttention。
- 一致性与可重放：随机种子控制、温度/Top-*策略、日志重放与离线诊断。

#### 数据流与控制流
- 数据流：请求→分词→前向→采样→流式输出；控制流：排队→分配→执行→回收。
- 高吞吐关键：减少小批量抖动、减少无效等待、提升显存命中、降低CPU/GPU搬运。

#### 多模型/多版本管理
- 同机多模型隔离：权重内存与显存隔离、共享权重（只读内存映射）与冷热切换。
- 版本灰度：金丝雀发布、特性开关、路由权重、回滚机制。

#### 失败与降级设计
- 熔断与限流、超时撤销、中断与重连、自动降级（小模型兜底/压缩上下文/降低温度）。


